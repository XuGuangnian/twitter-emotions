\documentclass{mproj}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{array,etoolbox}
\preto\tabular{\setcounter{magicrownumbers}{0}}
\newcounter{magicrownumbers}
\newcommand\rownumber{\stepcounter{magicrownumbers}\arabic{magicrownumbers}}
\setcounter{secnumdepth}{4}
\usepackage{longtable}
\usepackage{url}
\usepackage{listings}
\lstset{basicstyle={\ttfamily}}
\usepackage{csvsimple}
\usepackage{pgfplotstable,filecontents}
\usepackage{booktabs}
\usepackage{float}

\begin{document}
\title{Web Science Coursework - Social Media Emotion Data Set - Level M}
\author{Patrick Menlove - 2250066M}
\date{\today}
\maketitle

\newpage

\section{Introduction}
% Describe the software developed with appropriate details; if you have used code from elsewhere please specify it
% Specify the time and duration of data collected

This assignment concerns gathering cleanly labelled tweets for different emotion classes from Twitter. The solution used employs the use of the Twitter API and Google's Word2Vec.

The code uses several libraries (all of which can be found in the \lstinline{environment.yml} file), and uses MongoDB for data storage.

\section{Data crawl \& Rules}
\subsection{Twitter API}

The code uses the Twitter Streaming API to collect data in real-time when run. To be specific, the \lstinline!1.1/statuses/filter.json! endpoint (wrapped under the \lstinline{TwitterAPI} library - \url{https://github.com/geduldig/TwitterAPI}).

The reason this was chosen was that it would allow the code to ingest a significant volume of tweets and not be limited by twitter's premium search API rate limits. It also gives real-time, current, relevant tweets on which to do analyses.

The API allows the \lstinline{track} parameter to be specified, which can include various keywords to match. In the implementation, emotion label terms and emoticons are included in this parameter in order to filter results for each emotion.

It was important to deduplicate the data on the body of tweets, as the same tweet appears multiple times in the stream feed.

\subsection{Collected data}

% Give data statistics. A table with a.Total   and   individual   class   distribution   along   with   time period in which data collected.

Here is a table showing the distribution of assumed classes after processing, and the time ranges from which the tweets were collected. For some emotions, the criteria would not find as many as 150 tweets for the class, and disproportionately more for ``fear'' and ``happy''. Hence, these were truncated to 150.

\begin{figure}[H]
\centering
\pgfplotstabletypeset[
	col sep=comma,
	string type,
	every head row/.style={
        before row={%
            \toprule
        }
    },
    every last row/.style={
        after row=\bottomrule
    },
	display columns/0/.style={column name={\textbf{Emotion Label}}},
    display columns/1/.style={column name={\textbf{Count}}},
    display columns/2/.style={column name={\begin{flushleft}
    	\textbf{Date Range}
    \end{flushleft}}},
    display columns/3/.style={column name={\textbf{}}},
    header=false
]{../results/2b.csv}

\end{figure}

\subsection{Processing of Tweets}

\subsubsection{Clean Data}

In order to collect reasonably clean data, the code uses a series of search filters and transformations.

Initially, the \lstinline{track} parameter of the API call is given all the key words, so the streamed tweets are what twitter believes to have relevance to the kerywords/hashtags that have been identified as synonymous with the emotion label.

Then, these are initially filtered using a naive approach, by checking for the presence of other emotion labels' keywords in the tweets, and discarding the tweet if there is a match. This, in the simplest form, gives some confidence in the labels being reasonably clean.

The tweets are then persisted in MongoDB, and tweets are deduped with a uniqueness constraint on the tweet body. Then the \lstinline{process_tweets.py} file can be run, which makes a more accurate re-labelling of the tweets, by utilising Google's pre-trained Word2Vec. By computing the consine similarity of each ``emotion'' word with every word in the tweet, averaging and comparing the relative similarity scores for emotions, we can make a much better guess at the class of each tweet.

In addition to this, the \lstinline{process_tweets.py} file removes ``RT: @username'', any @ mentions and any ellipsis ... from the tweets.

Stemming or lemmaisation was considered, but this would not preserve the tweets human-readable nature for the crowd-sourcing. Though, the raw tweet text could be supplied for crowdsourcing and the lemmaised version be stored for computational use.

\subsubsection{Use of Emoticons}

Emoticons are used in the Twitter API stage of processing - since emojis can be passed as unicode strings, and the API accepts emojis to search for in the \lstinline{track} parameter.

Beyond this, emoticons are not taken into consideration in later processing steps. This is because the content of words similarity can be compared with Word2Vec but emoticons cannot.


\section{Crowdsourcing Method}
\subsection{Crowdsourcing Details}

Crowdsourcing is suitable for this problem as tweets are small, easy to parse sentences / pieces of information / streams of consciousness. Each crowdsourcing worker can analyse the emotion of a tweet independent of other workers, the work can be distributed easily.

The crowdsourcing micro task is simple - there is only one, to select the emotion label for a given tweet. The question ``Which word best describes the emotion of this tweet?'' was chosen. Each assignment carried a reward of \$0.01.



%Step3: configuration & result management

% Step 4: select the crowdsourcing platform to use
The crowdsourcing platform of choice was Amazon Mechanical Turk. It was chosen for its ease of use and economical rate. There was one issue with it in that MTurk rejected the CSV upload initially because of emojis in the text. In order to get round this and display emojis, I made use of this code found on Github \url{https://github.com/charman/mturk-emoji}. The designed Mechanical Turk HTML file is available in the \lstinline{mturk/} folder in the project repo.

% Step 5: Publish
% TEST MODE / DEBUG
% LIVE

\subsection{Results and Discussion}


%\bibliographystyle{plain}
%\bibliography{coursework}

\end{document}
